{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":61246,"databundleVersionId":6604167,"sourceType":"competition"}],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-10T14:37:16.979437Z","iopub.execute_input":"2023-12-10T14:37:16.980081Z","iopub.status.idle":"2023-12-10T14:37:16.990842Z","shell.execute_reply.started":"2023-12-10T14:37:16.980050Z","shell.execute_reply":"2023-12-10T14:37:16.989298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport random\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split,GridSearchCV,ShuffleSplit, cross_validate\nfrom sklearn.preprocessing import MinMaxScaler,OneHotEncoder,OrdinalEncoder,MaxAbsScaler,PolynomialFeatures,StandardScaler,QuantileTransformer,RobustScaler\nfrom sklearn.linear_model import LinearRegression, SGDRegressor,Ridge,Lasso,RidgeCV,LassoCV,ElasticNetCV\nfrom sklearn.pipeline import Pipeline,make_pipeline\nfrom sklearn.feature_selection import SelectKBest, VarianceThreshold, mutual_info_regression,f_regression\nfrom sklearn.compose import TransformedTargetRegressor\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import mean_squared_error,accuracy_score,r2_score,explained_variance_score,mean_absolute_error,median_absolute_error\nfrom sklearn.tree import DecisionTreeRegressor,ExtraTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor,BaggingRegressor,AdaBoostRegressor,HistGradientBoostingRegressor,StackingRegressor,ExtraTreesRegressor,VotingRegressor\nfrom sklearn.svm import SVR,NuSVR,LinearSVR\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.multioutput import MultiOutputRegressor\nfrom sklearn.decomposition import PCA\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\nimport statistics\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2023-12-10T14:37:11.466681Z","iopub.execute_input":"2023-12-10T14:37:11.467059Z","iopub.status.idle":"2023-12-10T14:37:14.479167Z","shell.execute_reply.started":"2023-12-10T14:37:11.467030Z","shell.execute_reply":"2023-12-10T14:37:14.477680Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_path = \"/kaggle/input/taxi-fare-guru-total-amount-prediction-challenge/train.csv\"\n# train_data = pd.read_csv(train_path)\n\n# y_train = train_data[\"total_amount\"]\n\n\n# dummy_regr = DummyRegressor(strategy=\"mean\")\n# dummy_regr.fit(x_train, y_train)\n# dummy_regr.predict(x_train)\n\n# dummy_regr.score(x_train,y_train)\n\n# test_data = pd.read_csv(\"/kaggle/input/taxi-fare-guru-total-amount-prediction-challenge/test.csv\")\n\n# prediction = dummy_regr.predict(test_data)\n\n# submission = pd.DataFrame(columns=['ID','total_amount'])\n\n# submission['ID'] = [i for i in range(1,len(prediction)+1) ]\n\n# submission['total_amount'] = prediction\n# submission.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T08:56:30.154816Z","iopub.execute_input":"2023-11-30T08:56:30.155496Z","iopub.status.idle":"2023-11-30T08:56:30.170494Z","shell.execute_reply.started":"2023-11-30T08:56:30.155446Z","shell.execute_reply":"2023-11-30T08:56:30.169080Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# READING THE TRAINING DATA\n\nx_train = pd.read_csv(\"/kaggle/input/taxi-fare-guru-total-amount-prediction-challenge/train.csv\")\ndata = x_train\ny_train = data[[\"total_amount\"]]\nprint(x_train.info())\nx_train.head()\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-10T14:37:22.016456Z","iopub.execute_input":"2023-12-10T14:37:22.017036Z","iopub.status.idle":"2023-12-10T14:37:22.872085Z","shell.execute_reply.started":"2023-12-10T14:37:22.016992Z","shell.execute_reply":"2023-12-10T14:37:22.870680Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<H2>PLOTTING HISTOGRAMS OF SOME COLUMNS FOR ANALYSIS</H2>","metadata":{}},{"cell_type":"code","source":"x_train['total_amount'].plot(kind='hist', bins=200, rwidth=0.9, color='#600000')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-10T14:37:43.351045Z","iopub.execute_input":"2023-12-10T14:37:43.351608Z","iopub.status.idle":"2023-12-10T14:37:43.863521Z","shell.execute_reply.started":"2023-12-10T14:37:43.351567Z","shell.execute_reply":"2023-12-10T14:37:43.862561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train['passenger_count'].plot(kind = 'hist',bins = 20,rwidth = 0.9)\nvalue_counts = x_train['passenger_count'].value_counts()\nfor index, value in value_counts.items():\n    plt.text(index, value, str(value), ha='center', va='bottom')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-10T14:37:48.836768Z","iopub.execute_input":"2023-12-10T14:37:48.837261Z","iopub.status.idle":"2023-12-10T14:37:49.123394Z","shell.execute_reply.started":"2023-12-10T14:37:48.837220Z","shell.execute_reply":"2023-12-10T14:37:49.120674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#BOX PLOT FOR VISUALLY DETECTING THE OUTLIERS\nx_train['trip_distance'].plot(kind='hist', bins=500, rwidth=0.9, color='#600000')\nplt.show()\nplt.figure(figsize=(8, 6))\nplt.boxplot(x_train['trip_distance']) \nplt.xlabel('Trip Distance')\nplt.title('Box Plot of Trip Distance')\nplt.show()\nx_train['trip_distance'].describe()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-10T14:37:53.353469Z","iopub.execute_input":"2023-12-10T14:37:53.353809Z","iopub.status.idle":"2023-12-10T14:37:54.453557Z","shell.execute_reply.started":"2023-12-10T14:37:53.353786Z","shell.execute_reply":"2023-12-10T14:37:54.452191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#REMOVING THE OUTLIERS\nmask_trip_distance = x_train['trip_distance'] <= 500\nx_train = x_train[mask_trip_distance]\nx_train['trip_distance'].describe()\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-10T14:37:58.563593Z","iopub.execute_input":"2023-12-10T14:37:58.564119Z","iopub.status.idle":"2023-12-10T14:37:58.603623Z","shell.execute_reply.started":"2023-12-10T14:37:58.564094Z","shell.execute_reply":"2023-12-10T14:37:58.601696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train['extra'].plot(kind='hist')\nplt.show()\nx_train['extra'].describe()","metadata":{"execution":{"iopub.status.busy":"2023-12-07T16:10:10.648046Z","iopub.execute_input":"2023-12-07T16:10:10.648461Z","iopub.status.idle":"2023-12-07T16:10:10.963556Z","shell.execute_reply.started":"2023-12-07T16:10:10.648429Z","shell.execute_reply":"2023-12-07T16:10:10.962659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train['tip_amount'].plot(kind='hist')\nplt.show()\n# x_train['tip_amount'].descirbe()","metadata":{"execution":{"iopub.status.busy":"2023-12-07T16:10:11.107555Z","iopub.execute_input":"2023-12-07T16:10:11.107987Z","iopub.status.idle":"2023-12-07T16:10:11.399518Z","shell.execute_reply.started":"2023-12-07T16:10:11.107951Z","shell.execute_reply":"2023-12-07T16:10:11.398358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train['tolls_amount'].plot(kind='hist')\nplt.show()\nx_train['tolls_amount'].describe()","metadata":{"execution":{"iopub.status.busy":"2023-12-07T16:10:11.662801Z","iopub.execute_input":"2023-12-07T16:10:11.663213Z","iopub.status.idle":"2023-12-07T16:10:11.961596Z","shell.execute_reply.started":"2023-12-07T16:10:11.663184Z","shell.execute_reply":"2023-12-07T16:10:11.960265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train['improvement_surcharge'].plot(kind='hist')\nplt.show()\nx_train['improvement_surcharge'].describe()","metadata":{"execution":{"iopub.status.busy":"2023-12-07T16:10:12.787760Z","iopub.execute_input":"2023-12-07T16:10:12.788163Z","iopub.status.idle":"2023-12-07T16:10:13.099592Z","shell.execute_reply.started":"2023-12-07T16:10:12.788132Z","shell.execute_reply":"2023-12-07T16:10:13.098259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train['congestion_surcharge'].plot(kind='hist')\nplt.show()\nx_train['congestion_surcharge'].describe()","metadata":{"execution":{"iopub.status.busy":"2023-12-07T16:10:13.101407Z","iopub.execute_input":"2023-12-07T16:10:13.102386Z","iopub.status.idle":"2023-12-07T16:10:13.394479Z","shell.execute_reply.started":"2023-12-07T16:10:13.102342Z","shell.execute_reply":"2023-12-07T16:10:13.393403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train['Airport_fee'].plot(kind='hist')\nplt.show()\nx_train['Airport_fee'].describe()","metadata":{"execution":{"iopub.status.busy":"2023-12-07T16:10:13.396518Z","iopub.execute_input":"2023-12-07T16:10:13.396841Z","iopub.status.idle":"2023-12-07T16:10:13.706933Z","shell.execute_reply.started":"2023-12-07T16:10:13.396814Z","shell.execute_reply":"2023-12-07T16:10:13.705814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# x_train.isna().sum()\n# # This is for handling all the NAN values:\n# ### data cleaning  ###\n\n# x_train.describe().transpose()\n# x_train['passenger_count'].plot(kind = 'hist',bins = 20,rwidth = 0.9)\n# plt.show()\n\n# random_numbers = np.random.randint(1, 3, size=len(x_train))\n# x_train['passenger_count'].fillna(pd.Series(random_numbers), inplace=True)\n\n# # Dealing with Outliers \n\n# def replace_invalid_values(value):\n#     if value > 8:\n#         return np.random.randint(1, 5)\n#     return value\n# x_train['passenger_count'] = x_train['passenger_count'].apply(replace_invalid_values)\n\n# x_train['passenger_count'].plot(kind = 'hist',bins = 10,rwidth = 0.9)\n# plt.show()\n\n\n# #for trip distance\n\n# print(x_train['trip_distance'].describe())\n# print(len(x_train))\n# # mask = (x_train['total_amount'] == 0) & (x_train['trip_distance'] == 0)\n# x_train = x_train[(x_train['total_amount'] != 0) & (x_train['trip_distance'] != 0)]\n# print(len(x_train))\n# # print(y_train['total_amount'].describe())\n# x_train['total_amount'].describe()\n# # x_train['fare_per_mile'] = data.apply(lambda row: 0 if row['total_amount'] == 0 else abs(row['trip_distance'] / row['total_amount']), axis=1)\n\n# # print(x_train['fare_per_mile'].describe())\n# x_train['fare_per_mile'] = np.where((x_train['total_amount'] > 0) & (x_train['trip_distance'] > 0),\n#                                     x_train['total_amount'] / x_train['trip_distance'],\n#                                     np.nan)\n# x_train['fare_per_mile'].describe()\n# # print(x_train['fare_per_mile'].isna().sum())\n# # x_train['total_amount'].describe()\n# import matplotlib.pyplot as plt\n# import pandas as pd\n\n# # Assuming 'x_train' is your DataFrame\n# # Replace 'x_train' with your actual DataFrame\n\n# # Create bins\n# bins = [10*i for i in range(21)]\n# # bins = [ 0, 2000, 4000, 6000, 8000,10000, 12000, 14000, 16000, 18000, 20000, 22000, 24000, 26000, 28000, 30000, 32000, 34000, 36000, 38000, 40000, 42000, 44000, 46000, 48000, 49100]\n\n# # Assign the 'fare_per_mile' values to bins\n# x_train['fare_per_mile_bin'] = pd.cut(x_train['fare_per_mile'], bins=bins)\n\n# # Plot the histogram with count labels\n# plt.figure(figsize=(10, 6))\n# ax = x_train['fare_per_mile_bin'].value_counts().sort_index().plot(kind='bar', edgecolor='black')\n\n# # Display count labels over each bar\n# for p in ax.patches:\n#     ax.annotate(str(p.get_height()), (p.get_x() + p.get_width() / 2., p.get_height()),\n#                 ha='center', va='baseline', xytext=(0, 5), textcoords='offset points')\n\n# # Set plot labels and title\n# plt.xlabel('fare_per_mile Bins')\n# plt.ylabel('Count')\n# plt.title('Distribution of fare_per_mile')\n\n# # Show the plot\n# plt.show()\n\n# # # Assuming 'x_train' is your DataFrame\n# # # Replace 'x_train' with your actual DataFrame\n\n# # # Drop rows with NaN values in 'fare_per_mile_bin'\n# # x_train_cleaned = x_train.dropna(subset=['fare_per_mile_bin'])\n\n# # # Create a boolean mask for the specified bin range\n# # bin_range = pd.Interval(2000, 4000, closed='right')\n# # mask_bin_2000_4000 = x_train_cleaned['fare_per_mile_bin'].apply(lambda x: x in bin_range)\n\n# # # Filter rows based on the mask\n# # rows_bin_2000_4000 = x_train_cleaned[mask_bin_2000_4000]\n\n# # # Print the selected rows\n# # print(rows_bin_2000_4000)\n\n# x_train[(x_train['total_amount'] <= 0) & (x_train['trip_distance'] > 50)]\n# x_train[(x_train['total_amount'] <= 0) & (x_train['trip_distance'] > 0) & (x_train['trip_distance'] <1)]\n\n# x_train[x_train['trip_distance'] == 0]\n# data['total_amount'].describe()\n# def update_total_amount(row):\n#     # if row['total_amount'] == 0 and row['trip_distance'] < 300:\n#     if row['total_amount'] <= 0:\n#         return row['trip_distance'] * 16\n#     return row['total_amount']\n# x_train['total_amount'] = x_train.apply(update_total_amount, axis=1)\n# x_train['total_amount'].describe()\n# x_train[x_train['total_amount'] == 0]\n# x_train['trip_distance'].describe()\n\n# def update_trip_distance(row):\n\n#     if row['trip_distance'] == 0 or row['trip_distance'] > 150 or row['total_amount'] / row['trip_distance'] > 200:\n#         return row['total_amount'] / 16\n#     else:\n#         return row['trip_distance']\n# x_train['trip_distance'] = x_train.apply(update_trip_distance, axis=1)\n\n\n# print(x_train['trip_distance'].describe())\n\n\n\n# import matplotlib.pyplot as plt\n# import pandas as pd\n\n# # Assuming 'x_train' is your DataFrame\n# # Replace 'x_train' with your actual DataFrame\n\n# # Create bins\n# bins = [10*i for i in range(21)]\n# # bins = [ 0, 2000, 4000, 6000, 8000,10000, 12000, 14000, 16000, 18000, 20000, 22000, 24000, 26000, 28000, 30000, 32000, 34000, 36000, 38000, 40000, 42000, 44000, 46000, 48000, 49100]\n\n# # Assign the 'fare_per_mile' values to bins\n# x_train['trip_distance_bin'] = pd.cut(x_train['trip_distance'], bins=bins)\n\n# # Plot the histogram with count labels\n# plt.figure(figsize=(10, 6))\n# ax = x_train['trip_distance_bin'].value_counts().sort_index().plot(kind='bar', edgecolor='black')\n\n# # Display count labels over each bar\n# for p in ax.patches:\n#     ax.annotate(str(p.get_height()), (p.get_x() + p.get_width() / 2., p.get_height()),\n#                 ha='center', va='baseline', xytext=(0, 5), textcoords='offset points')\n\n# # Set plot labels and title\n# plt.xlabel('trip_distance Bins')\n# plt.ylabel('Count')\n# plt.title('Distribution of trip_distance_bin')\n\n# # Show the plot\n# plt.show()\n\n# # for RateCodeID\n# choices = [1, 2, 3, 4, 5, 99]\n# x_train['RatecodeID'].fillna(random.choice(choices), inplace=True)\n# x_train['RatecodeID'].isna().sum()\n# x_train.isna().sum()\n# x_train = x_train.drop(columns=['fare_per_mile_bin','trip_distance_bin'])\n# x_train.isna().sum()\n# x_train['extra'] = x_train['extra'].abs()\n# x_train['tolls_amount'] = x_train['tolls_amount'].abs()\n# x_train['improvement_surcharge'] = x_train['improvement_surcharge'].abs()\n# x_train['congestion_surcharge'] = x_train['congestion_surcharge'].abs()\n# x_train['Airport_fee'] = x_train['Airport_fee'].abs()\n\n# def impute_congestion_charge(row):\n#     if pd.isna(row['congestion_surcharge']):\n#         return random.choice([0, 2.5])\n#     else:\n#         return row['congestion_surcharge']\n\n# x_train['congestion_surcharge'] = x_train.apply(impute_congestion_charge, axis=1)\n# def impute_congestion_charge(row):\n#     if pd.isna(row['Airport_fee']):\n#         return random.choice([0, 1.75])\n#     else:\n#         return row['Airport_fee']\n\n# # x_train['Airport_fee'] = x_train.apply(impute_congestion_charge, axis=1)\n# x_train.isna().sum()\n# # # Assuming 'x_train' is your DataFrame\n# # initial_row_count = len(x_train)\n\n# # # Drop rows with NaN values in 'trip_distance' column\n# # x_train.dropna(subset=['trip_distance'], inplace=True)\n\n# # # Calculate the number of rows dropped\n# # rows_dropped = initial_row_count - len(x_train)\n\n# # # Display the number of rows dropped\n# # print(f'{rows_dropped} rows were dropped.')\n\n# # import matplotlib.pyplot as plt\n\n\n# # data2['total_amount'] = data2['total_amount'].apply(abs)\n\n# # plt.figure(figsize=(8, 6))  # Optional: Set the figure size\n\n# # # Create a scatter plot\n# # plt.scatter(data['trip_distance'], data['total_amount'], alpha=0.5)\n# # plt.xlabel('trip_distance')\n# # plt.ylabel('total_amount')\n# # plt.title('Scatter Plot between Column 1 and Column 2')\n# # plt.xlim(0.5, 100)\n# # plt.grid(True)\n# # plt.show()\n# #cleaning the date and time column\n\n# x_train['tpep_pickup_datetime'] = pd.to_datetime(x_train['tpep_pickup_datetime'], format='%Y-%m-%d %H:%M:%S')\n# x_train['tpep_dropoff_datetime'] = pd.to_datetime(x_train['tpep_dropoff_datetime'], format='%Y-%m-%d %H:%M:%S')\n\n# invalid_entries = x_train[x_train['tpep_pickup_datetime'] > x_train['tpep_dropoff_datetime']]\n# for index in invalid_entries.index:\n#     temp = x_train.at[index, 'tpep_pickup_datetime']\n#     x_train.at[index, 'tpep_pickup_datetime'] = x_train.at[index, 'tpep_dropoff_datetime']\n#     x_train.at[index, 'tpep_dropoff_datetime'] = temp\n# # invalid_entries = x_train[x_train['tpep_pickup_datetime'] > x_train['tpep_dropoff_datetime']]\n\n# print(invalid_entries)\n\n\n# x_train.info()\n# x_train['journey_duration'] = x_train['tpep_dropoff_datetime'] - x_train['tpep_pickup_datetime']\n\n# # Filter entries where journey duration is greater than one day\n# long_duration_entries = x_train[x_train['journey_duration'] > pd.Timedelta('1 day')]\n\n# long_duration_entries\n\n\n\n# (x_train.sort_values(by=['journey_duration'], ascending=False)).head()\n# # print(long_duration_entries[['tpep_pickup_datetime', 'tpep_dropoff_datetime', 'trip_distance']])\n\n# x_train = x_train[~((x_train['journey_duration'] > pd.Timedelta('1 day')) & (x_train['trip_distance'] < 5))]\n# x_train.reset_index(drop=True, inplace=True)\n\n# long_duration_entries = x_train[x_train['journey_duration'] > pd.Timedelta('1 day')]\n# x_train['travel_time'] = (((pd.to_datetime(x_train['tpep_dropoff_datetime']))- (pd.to_datetime(x_train['tpep_pickup_datetime']))).dt.total_seconds()/60)\n# x_train['travel_time']=x_train['travel_time'].abs()\n\n# def hr_to_time(hr):\n#     if hr >= 0 and hr < 6:\n#         return 0\n#     if hr >=6 and hr <= 11:\n#         return 1\n#     elif hr >=11 and hr <= 17:\n#         return 2\n#     elif hr >=17 and hr <= 23:\n#         return 3\n#     else:\n#         return 4\n# x_train['pickup_hr'] = pd.to_datetime(x_train['tpep_pickup_datetime']).dt.hour\n# x_train['pickup_time'] = x_train['pickup_hr'].apply(hr_to_time)\n\n# x_train['dropoff_hr'] = pd.to_datetime(x_train['tpep_dropoff_datetime']).dt.hour\n# x_train['dropoff_time'] = x_train['dropoff_hr'].apply(hr_to_time)\n\n\n# x_train['date'] = pd.to_datetime(x_train['tpep_pickup_datetime']).dt.day\n# # x_train['date_number'] = x_train['date'].apply(date_to_number)\n\n\n# x_train['day_name'] = pd.to_datetime(x_train['tpep_pickup_datetime']).dt.day_name()\n# # x_train['day_name_number'] = x_train['day_name'].apply(dayname_to_number)\n# x_train = pd.get_dummies(x_train, columns=['day_name'])\n\n\n# def month_to_number(m):\n#     if m == 6:\n#         return 0\n#     elif m == 7 :\n#         return 1\n#     else:\n#         return 2\n    \n# x_train['month'] = pd.to_datetime(x_train['tpep_pickup_datetime']).dt.month\n# # x_train['month_number'] = x_train['month'].apply(month_to_number)\n# x_train.head()\n# x_train.columns\n\n# x_train['store_and_fwd_flag'].fillna('N',inplace=True)\n\n# def flag_to_number(f):\n#     if f == 'N':\n#         return 0\n#     elif f == 'Y' :\n#         return 1\n#     else:\n#         return 2\n# x_train['flag_number'] = x_train['store_and_fwd_flag'].apply(flag_to_number)\n# x_train['payment_type'].replace('unknown', 'Credit Card', inplace = True)\n# def payment_to_number(p):\n#     if p == 'Credit Card':\n#         return 0\n#     elif p == 'Cash':\n#         return 1\n#     elif p == 'Wallet':\n#         return 2\n#     else:\n#         return 3\n\n# x_train['payment_number'] = x_train['payment_type'].apply(payment_to_number)\n\n\n# columns_to_exclude = ['tpep_pickup_datetime', 'tpep_dropoff_datetime', 'payment_type','store_and_fwd_flag','journey_duration','fare_per_mile', 'pickup_hr', 'dropoff_hr', 'date', 'month']\n# X = x_train.drop(['total_amount'] + columns_to_exclude, axis=1)  # Exclude 'total_amount' and specified columns\n# y = x_train['total_amount']\n# X = X.astype('float64')\n# print(len(X.columns))\n# # X.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T08:56:35.401386Z","iopub.execute_input":"2023-11-30T08:56:35.402221Z","iopub.status.idle":"2023-11-30T08:56:35.420416Z","shell.execute_reply.started":"2023-11-30T08:56:35.402185Z","shell.execute_reply":"2023-11-30T08:56:35.418921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*******************************************************************************","metadata":{}},{"cell_type":"markdown","source":"&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n","metadata":{}},{"cell_type":"code","source":"# param_grid = {\n#     'n_estimators': [10, 50, 100],\n#     'max_depth': [None, 10, 20],\n# #     'min_samples_split': [2, 5, 10],\n# #     'min_samples_leaf': [1, 2, 4]\n# #     'pca__n_components':[2,4,6,8,10]\n# }\n\n\n# rf_regressor = RandomForestRegressor(random_state=42)\n\n\n# grid_search = GridSearchCV(estimator=rf_regressor, param_grid=param_grid, cv=4, scoring='r2',n_jobs=-1)\n# grid_search.fit(X_train, y_train)\n\n\n# best_params = grid_search.best_params_","metadata":{"execution":{"iopub.status.busy":"2023-11-30T08:56:35.422307Z","iopub.execute_input":"2023-11-30T08:56:35.422740Z","iopub.status.idle":"2023-11-30T08:56:35.440327Z","shell.execute_reply.started":"2023-11-30T08:56:35.422698Z","shell.execute_reply":"2023-11-30T08:56:35.439171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"################################################################################\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T08:56:35.441594Z","iopub.execute_input":"2023-11-30T08:56:35.442847Z","iopub.status.idle":"2023-11-30T08:56:35.453722Z","shell.execute_reply.started":"2023-11-30T08:56:35.442807Z","shell.execute_reply":"2023-11-30T08:56:35.452485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train = pd.read_csv('/kaggle/input/taxi-fare-guru-total-amount-prediction-challenge/train.csv')","metadata":{"execution":{"iopub.status.busy":"2023-12-10T14:44:13.514395Z","iopub.execute_input":"2023-12-10T14:44:13.514887Z","iopub.status.idle":"2023-12-10T14:44:13.991801Z","shell.execute_reply.started":"2023-12-10T14:44:13.514849Z","shell.execute_reply":"2023-12-10T14:44:13.989966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<H3>HANDLING THE DATE AND TIME COLUMN</H3>\nHERE THE PICKUP AND DROP TIME COLUMN IS CONVERTED TO DURATION COLUMN, CREATING A NEW FEATURE WHICH IS MORE USEFUL","metadata":{}},{"cell_type":"code","source":"x_train['tpep_pickup_datetime'] = pd.to_datetime(x_train['tpep_pickup_datetime'])\nx_train['tpep_dropoff_datetime'] = pd.to_datetime(x_train['tpep_dropoff_datetime'])\n\n\nx_train['duration'] = (x_train['tpep_dropoff_datetime'] - x_train['tpep_pickup_datetime']).apply(lambda x: x.total_seconds())\n\n\nx_train['duration'] = x_train['duration'].abs()\n# x_train['duration'].head(10)\nx_train = x_train.drop(['tpep_pickup_datetime','tpep_dropoff_datetime'],axis = 1)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-10T14:44:16.262240Z","iopub.execute_input":"2023-12-10T14:44:16.262798Z","iopub.status.idle":"2023-12-10T14:44:16.862874Z","shell.execute_reply.started":"2023-12-10T14:44:16.262754Z","shell.execute_reply":"2023-12-10T14:44:16.861940Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ENCODING THE CATEGORICAL COLUMNS","metadata":{}},{"cell_type":"code","source":"x_train = pd.get_dummies(x_train, columns=['store_and_fwd_flag', 'payment_type'], \n                         prefix=['store_and_fwd', 'payment_type'])","metadata":{"execution":{"iopub.status.busy":"2023-12-10T14:44:20.696585Z","iopub.execute_input":"2023-12-10T14:44:20.697057Z","iopub.status.idle":"2023-12-10T14:44:20.750744Z","shell.execute_reply.started":"2023-12-10T14:44:20.697019Z","shell.execute_reply":"2023-12-10T14:44:20.748327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# x_train['extra'] = x_train['extra'].abs()\n# x_train['tolls_amount'] = x_train['tolls_amount'].abs()\n# x_train['improvement_surcharge'] = x_train['improvement_surcharge'].abs()\n# x_train['congestion_surcharge'] = x_train['congestion_surcharge'].abs()\n# x_train['Airport_fee'] = x_train['Airport_fee'].abs()\nx_train = x_train.astype('float64') #CONVERTING ALL THE COLUMNS TO SAME TYPE\nx_train.info()\nx_train.isna().sum()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-10T14:44:23.657006Z","iopub.execute_input":"2023-12-10T14:44:23.657538Z","iopub.status.idle":"2023-12-10T14:44:23.698019Z","shell.execute_reply.started":"2023-12-10T14:44:23.657497Z","shell.execute_reply":"2023-12-10T14:44:23.696483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ii = IterativeImputer(max_iter = 15)\nx_train_imputed = ii.fit_transform(x_train)\nx_train = pd.DataFrame(x_train_imputed, columns=x_train.columns)\n#HEAT MAP FOR CHEKCING THE CORRELATION BETWEEN COLUMNS TO SEE RELEVANCE OF FEATURES.\ncorr = x_train.corr()\nplt.figure(figsize=(12, 10))\nsns.heatmap(corr, cmap='coolwarm', annot=True, fmt=\".2f\", linewidths=0.5)\nplt.title('Correlation Heatmap of x_train')\nplt.show()\nX = x_train.drop('total_amount',axis = 1)\nY = x_train['total_amount']\nprint(X.isna().sum())\nprint(Y.isna().sum())\n","metadata":{"execution":{"iopub.status.busy":"2023-12-10T14:44:28.099090Z","iopub.execute_input":"2023-12-10T14:44:28.099605Z","iopub.status.idle":"2023-12-10T14:44:33.860881Z","shell.execute_reply.started":"2023-12-10T14:44:28.099569Z","shell.execute_reply":"2023-12-10T14:44:33.859794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = x_train['total_amount']\nx_train = x_train.drop('total_amount',axis=1)\n\nx_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-10T14:44:43.573878Z","iopub.execute_input":"2023-12-10T14:44:43.574206Z","iopub.status.idle":"2023-12-10T14:44:43.625070Z","shell.execute_reply.started":"2023-12-10T14:44:43.574183Z","shell.execute_reply":"2023-12-10T14:44:43.623648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"RANDOM FOREST","metadata":{}},{"cell_type":"code","source":"rf = RandomForestRegressor()\nrf_ = RandomForestRegressor()\nrf.fit(x_train,y_train)\nrf_.fit(X,Y)\ny_pred_rf = rf.predict(x_test)\nr2 = r2_score(y_test,y_pred_rf)\nrme = np.sqrt(mean_squared_error(y_test,y_pred_rf))\nprint(\"R2 Score for the Random Forest Regressor is:\",r2)\nprint(\"RMSE with Random Forest Regressor is:\",rme)\nplt.figure(figsize=(8, 6))\nplt.scatter(y_test, y_pred_rf, alpha=0.5)\nplt.title('Actual vs Predicted Values')\nplt.xlabel('Actual Values')\nplt.ylabel('Predicted Values')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-10T14:44:54.654047Z","iopub.execute_input":"2023-12-10T14:44:54.654459Z","iopub.status.idle":"2023-12-10T14:49:20.490796Z","shell.execute_reply.started":"2023-12-10T14:44:54.654428Z","shell.execute_reply":"2023-12-10T14:49:20.489367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"BAGGING REGRESSOR","metadata":{}},{"cell_type":"code","source":"br = BaggingRegressor()\nbr_ = BaggingRegressor()\nbr.fit(x_train,y_train)\nbr_.fit(X,Y)\ny_pred_br = br.predict(x_test)\nr2 = r2_score(y_test,y_pred_br)\nrme = np.sqrt(mean_squared_error(y_test,y_pred_br))\nprint(\"R2 Score for the Random Forest Regressor is:\",r2)\nprint(\"RMSE with Random Forest Regressor is:\",rme)\nplt.figure(figsize=(8, 6))\nplt.scatter(y_test, y_pred_br, alpha=0.5)\nplt.title('Actual vs Predicted Values')\nplt.xlabel('Actual Values')\nplt.ylabel('Predicted Values')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T09:02:08.549855Z","iopub.status.idle":"2023-11-30T09:02:08.550383Z","shell.execute_reply.started":"2023-11-30T09:02:08.550104Z","shell.execute_reply":"2023-11-30T09:02:08.550129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"GRID SEARCH ON EXTRATREE REGRESSOR","metadata":{}},{"cell_type":"code","source":"# #USING PIPELINE AND GRID SEARCH CV\npipeline = Pipeline([ ('ss', StandardScaler()), ('poly',PolynomialFeatures(degree= 2)),('pca',PCA()),('r',ExtraTreesRegressor(n_jobs = -1)) ])\nparameters = dict(r__n_estimators=[100,150],pca__n_components=[5,10])\ngrid_search = GridSearchCV(pipeline, parameters, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\ngrid_search.fit(x_train,y_train)\ngrid_search_pred = grid_search.predict(x_test)\nr2 = r2_score(y_test,grid_search_pred)\nrme = np.sqrt(mean_squared_error(y_test,grid_search_pred))\nbest_params = grid_search.best_params_\nprint(\"BEST PARAMETERS ARE:\", best_params)\nprint(\"R2 Score for the Random Forest Regressor is:\",r2)\nprint(\"RMSE with Random Forest Regressor is:\",rme)\nplt.figure(figsize=(8, 6))\nplt.scatter(y_test, grid_search_pred, alpha=0.5)\nplt.title('Actual vs Predicted Values')\nplt.xlabel('Actual Values')\nplt.ylabel('Predicted Values')\nplt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T09:02:08.551467Z","iopub.status.idle":"2023-11-30T09:02:08.551890Z","shell.execute_reply.started":"2023-11-30T09:02:08.551689Z","shell.execute_reply":"2023-11-30T09:02:08.551709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1>ACTUAL TESTING DATA</h1>\n***FOR SUBMISSION***","metadata":{}},{"cell_type":"code","source":"x_test = pd.read_csv('/kaggle/input/taxi-fare-guru-total-amount-prediction-challenge/test.csv')","metadata":{"execution":{"iopub.status.busy":"2023-11-30T09:02:08.552921Z","iopub.status.idle":"2023-11-30T09:02:08.553355Z","shell.execute_reply.started":"2023-11-30T09:02:08.553143Z","shell.execute_reply":"2023-11-30T09:02:08.553163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_test['tpep_pickup_datetime'] = pd.to_datetime(x_test['tpep_pickup_datetime'])\nx_test['tpep_dropoff_datetime'] = pd.to_datetime(x_test['tpep_dropoff_datetime'])\n\nx_test['duration'] = (x_test['tpep_dropoff_datetime'] - x_test['tpep_pickup_datetime']).apply(lambda x: x.total_seconds())\n\nx_test['duration'] = x_test['duration'].abs()\nx_test = x_test.drop(['tpep_pickup_datetime','tpep_dropoff_datetime'],axis = 1)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T09:02:08.554467Z","iopub.status.idle":"2023-11-30T09:02:08.554881Z","shell.execute_reply.started":"2023-11-30T09:02:08.554676Z","shell.execute_reply":"2023-11-30T09:02:08.554694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# x_test['store_and_fwd_flag'].fillna('N',inplace=True)\n# x_test['payment_type'].fillna('Credit Card',inplace=True)\n# x_test['passenger_count'] = x_test['passenger_count'].apply(replace_invalid_values)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T09:02:08.555833Z","iopub.status.idle":"2023-11-30T09:02:08.556281Z","shell.execute_reply.started":"2023-11-30T09:02:08.556039Z","shell.execute_reply":"2023-11-30T09:02:08.556081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_test = pd.get_dummies(x_test, columns=['store_and_fwd_flag', 'payment_type'], \n                         prefix=['store_and_fwd', 'payment_type'])","metadata":{"execution":{"iopub.status.busy":"2023-11-30T09:02:08.558097Z","iopub.status.idle":"2023-11-30T09:02:08.559303Z","shell.execute_reply.started":"2023-11-30T09:02:08.559020Z","shell.execute_reply":"2023-11-30T09:02:08.559073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# x_test['extra'] = x_test['extra'].abs()\n# x_test['tolls_amount'] = x_test['tolls_amount'].abs()\n# x_test['improvement_surcharge'] = x_test['improvement_surcharge'].abs()\n# x_test['congestion_surcharge'] = x_test['congestion_surcharge'].abs()\n# x_test['Airport_fee'] = x_test['Airport_fee'].abs()\nx_test = x_test.astype('float64')\nx_test.info()\nx_test.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T09:02:08.560876Z","iopub.status.idle":"2023-11-30T09:02:08.561655Z","shell.execute_reply.started":"2023-11-30T09:02:08.561443Z","shell.execute_reply":"2023-11-30T09:02:08.561464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_test_imputed = ii.fit_transform(x_test)\nx_test = pd.DataFrame(x_test_imputed, columns=x_test.columns)\nx_test.info()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T09:02:08.562998Z","iopub.status.idle":"2023-11-30T09:02:08.563743Z","shell.execute_reply.started":"2023-11-30T09:02:08.563525Z","shell.execute_reply":"2023-11-30T09:02:08.563545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ypredict = rf_.predict(x_test) #score was = 0.93289\n# ypredict = br_.predict(x_test) score was = 0.92633\n\nprint(len(ypredict))\n\n\nsubmission = pd.DataFrame(columns = [\"ID\",\"total_amount\"])\nsubmission[\"ID\"] = [i for i in range(1,len(ypredict)+1)]\nsubmission[\"total_amount\"] = pd.DataFrame(ypredict)\nsubmission.to_csv('submission.csv',index=False)\nprint(\"Done\")","metadata":{"execution":{"iopub.status.busy":"2023-11-30T09:02:08.565404Z","iopub.status.idle":"2023-11-30T09:02:08.568231Z","shell.execute_reply.started":"2023-11-30T09:02:08.567992Z","shell.execute_reply":"2023-11-30T09:02:08.568014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}